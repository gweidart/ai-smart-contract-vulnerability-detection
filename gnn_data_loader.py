# gnn_data_loader.py

import os
import torch
from torch_geometric.data import Data, InMemoryDataset
from torch_geometric.loader import DataLoader
from concurrent.futures import ThreadPoolExecutor
from rich_utils import add_debug_message, create_progress_bar
from labeler import label_vulnerabilities
import re

class SmartContractDataset(InMemoryDataset):
    def __init__(self, root, transform=None, pre_transform=None):
        super(SmartContractDataset, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    def raw_file_names(self):
        return [f'contract{i}' for i in range(1, 44)]

    @property
    def processed_file_names(self):
        return ['data.pt']

    def download(self):
        pass

    def process(self):
        data_list = []

        with ThreadPoolExecutor() as executor:
            futures = []
            dataset_dir = './dataset'
            for i in range(1, 44):
                folder_name = f"contract{i}"
                folder_path = os.path.join(dataset_dir, folder_name)
                if os.path.isdir(folder_path):
                    for file_name in os.listdir(folder_path):
                        if file_name.endswith('.sol'):
                            file_path = os.path.join(folder_path, file_name)
                            futures.append(executor.submit(self.load_file, file_path))
            
            with create_progress_bar() as progress:
                task = progress.add_task("Loading files...", total=len(futures))
                for future in futures:
                    data = future.result()
                    if data is not None:
                        data_list.append(data)
                    progress.advance(task)

        try:
            data, slices = self.collate(data_list)
            torch.save((data, slices), self.processed_paths[0])
            add_debug_message(f"[bold green]Dataset processed successfully.")
        except Exception as e:
            add_debug_message(f"[bold red]Error processing dataset: {e}")

    def load_file(self, file_path):
        try:
            with open(file_path, 'r') as file:
                source_code = file.read()

                nodes = self.extract_features(source_code)
                edge_index = self.extract_edges(source_code)
                
                labels = label_vulnerabilities(source_code)

                x = torch.tensor([self.node_feature_vector(node) for node in nodes], dtype=torch.float)
                y = torch.tensor(labels, dtype=torch.float)

                data = Data(x=x, edge_index=edge_index, y=y)

                return data
        except Exception as e:
            add_debug_message(f"[bold red]Error loading file {file_path}: {e}")
            return None

    def extract_features(self, source_code):
        features = []
        try:
            function_pattern = re.compile(r'function\s+\w+')
            for line in source_code.split('\n'):
                if function_pattern.search(line):
                    features.append([1])
                else:
                    features.append([0])
        except Exception as e:
            add_debug_message(f"[bold red]Error extracting features: {e}")
        return features

    def extract_edges(self, source_code):
        try:
            lines = source_code.split('\n')
            num_nodes = len(lines)
            edge_index = []
            for i, line in enumerate(lines):
                if 'function' in line:
                    for j in range(i+1, num_nodes):
                        edge_index.append((i, j))
                else:
                    if i < num_nodes - 1:
                        edge_index.append((i, i + 1))
            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
            return edge_index
        except Exception as e:
            add_debug_message(f"[bold red]Error extracting edges: {e}")
            return torch.tensor([])

    def node_feature_vector(self, node):
        try:
            if node == 'function':
                return [1, 0]
            else:
                return [0, 1]
        except Exception as e:
            add_debug_message(f"[bold red]Error creating node feature vector: {e}")
            return [0, 0]

def load_gnn_dataset(batch_size=32):
    try:
        dataset = SmartContractDataset(root='./dataset')
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
        add_debug_message(f"[bold green]GNN dataset loaded successfully.")
        return loader
    except Exception as e:
        add_debug_message(f"[bold red]Error creating GNN data loader: {e}")
        return None
