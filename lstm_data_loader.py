# lstm_data_loader.py

import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import LabelEncoder, StandardScaler
from labeler import label_vulnerabilities
from rich_utils import add_debug_message, create_progress_bar
import os
import numpy as np

class SmartContractDataset(Dataset):
    def __init__(self, data_dir):
        self.data, self.labels = self.load_data(data_dir)
        
    def load_data(self, data_dir):
        data = []
        labels = []

        try:
            with create_progress_bar() as progress:
                task = progress.add_task("Loading files...", total=len(os.listdir(data_dir)))

                for file_name in os.listdir(data_dir):
                    if file_name.endswith('.sol'):
                        file_path = os.path.join(data_dir, file_name)
                        try:
                            with open(file_path, 'r') as file:
                                source_code = file.read()
                                data.append(source_code)
                                labels.append(label_vulnerabilities(source_code))
                        except Exception as e:
                            add_debug_message(f"[bold red]Error loading file {file_path}: {e}")
                        
                        progress.advance(task)

                # Flatten the lists and encode labels
                data = np.array(data)
                labels = np.array(labels)
                label_encoder = LabelEncoder()
                labels = label_encoder.fit_transform(labels.flatten())

                # Normalize data
                scaler = StandardScaler()
                data = scaler.fit_transform(data.reshape(-1, 1)).reshape(-1)

        except Exception as e:
            add_debug_message(f"[bold red]Error loading dataset: {e}")

        return data, labels

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)

def load_lstm_dataset(data_dir, batch_size=32):
    try:
        dataset = SmartContractDataset(data_dir)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
        return loader
    except Exception as e:
        add_debug_message(f"[bold red]Error creating data loader: {e}")
        return None
